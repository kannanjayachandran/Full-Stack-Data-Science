{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" >  <font color=\"Orange\"> Numpy ~ Exercises </font> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random batch shape: (4, 5)\n",
      "Batch:\n",
      "[[ 0  1  2  3  4]\n",
      " [25 26 27 28 29]\n",
      " [30 31 32 33 34]\n",
      " [ 5  6  7  8  9]]\n",
      "\n",
      "Subset features shape: (20, 3)\n",
      "First 5 rows of subset:\n",
      "[[ 0  2  4]\n",
      " [ 5  7  9]\n",
      " [10 12 14]\n",
      " [15 17 19]\n",
      " [20 22 24]]\n"
     ]
    }
   ],
   "source": [
    "# Select random samples (common in mini-batch training)\n",
    "X = np.arange(100).reshape(20, 5)  # 20 samples, 5 features\n",
    "batch_indices = np.random.choice(20, size=4, replace=False)\n",
    "batch = X[batch_indices]\n",
    "print(f\"Random batch shape: {batch.shape}\")\n",
    "print(f\"Batch:\\n{batch}\")\n",
    "\n",
    "# Select specific features\n",
    "feature_indices = [0, 2, 4]  # Select features 0, 2, 4\n",
    "X_subset = X[:, feature_indices]\n",
    "print(f\"\\nSubset features shape: {X_subset.shape}\")\n",
    "print(f\"First 5 rows of subset:\\n{X_subset[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Normalization (Z-score) using broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n",
      "Mean per feature: [5.5 6.5 7.5]\n",
      "Std per feature: [3.35410197 3.35410197 3.35410197]\n",
      "\n",
      "Normalized data:\n",
      "[[-1.34164079 -1.34164079 -1.34164079]\n",
      " [-0.4472136  -0.4472136  -0.4472136 ]\n",
      " [ 0.4472136   0.4472136   0.4472136 ]\n",
      " [ 1.34164079  1.34164079  1.34164079]]\n",
      "New mean per feature: [0. 0. 0.]\n",
      "New std per feature: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Normalize features: (X - mean) / std\n",
    "X = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9],\n",
    "              [10, 11, 12]], dtype=float)\n",
    "\n",
    "# Compute mean and std along axis 0 (for each feature)\n",
    "mean = X.mean(axis=0)  # Shape: (3,)\n",
    "std = X.std(axis=0)    # Shape: (3,)\n",
    "\n",
    "print(f\"Original data:\\n{X}\")\n",
    "print(f\"Mean per feature: {mean}\")\n",
    "print(f\"Std per feature: {std}\")\n",
    "\n",
    "# Broadcasting: (4,3) - (3,) -> (4,3) - (1,3) -> (4,3)\n",
    "X_normalized = (X - mean) / std\n",
    "print(f\"\\nNormalized data:\\n{X_normalized}\")\n",
    "print(f\"New mean per feature: {X_normalized.mean(axis=0)}\")\n",
    "print(f\"New std per feature: {X_normalized.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-max scaled:\n",
      "[[0.         0.        ]\n",
      " [0.33333333 0.33333333]\n",
      " [0.66666667 0.66666667]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Scale features to [0, 1]: (X - min) / (max - min)\n",
    "X = np.array([[1, 2],\n",
    "              [3, 4],\n",
    "              [5, 6],\n",
    "              [7, 8]], dtype=float)\n",
    "\n",
    "X_min = X.min(axis=0)  # Shape: (2,)\n",
    "X_max = X.max(axis=0)  # Shape: (2,)\n",
    "\n",
    "X_scaled = (X - X_min) / (X_max - X_min)\n",
    "print(f\"Min-max scaled:\\n{X_scaled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UFuncs in Machine learning\n",
    "\n",
    "- Activation Functions\n",
    "- Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [-2 -1  0  1  2]\n",
      "ReLU: [0 0 0 1 2]\n",
      "Sigmoid: [0.11920292 0.26894142 0.5        0.73105858 0.88079708]\n",
      "Tanh: [-0.96402758 -0.76159416  0.          0.76159416  0.96402758]\n",
      "\n",
      "Logits: [2.  1.  0.1]\n",
      "Softmax: [0.65900114 0.24243297 0.09856589]\n",
      "Sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ReLU (Rectified Linear Unit)\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Tanh\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Softmax (for classification)\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
    "    return exp_x / np.sum(exp_x, axis=0)\n",
    "\n",
    "# Test activation functions\n",
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"ReLU: {relu(x)}\")\n",
    "print(f\"Sigmoid: {sigmoid(x)}\")\n",
    "print(f\"Tanh: {tanh(x)}\")\n",
    "\n",
    "# Softmax on logits\n",
    "logits = np.array([2.0, 1.0, 0.1])\n",
    "print(f\"\\nLogits: {logits}\")\n",
    "print(f\"Softmax: {softmax(logits)}\")\n",
    "print(f\"Sum: {np.sum(softmax(logits))}\")  # Should be 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector x: [1 2 3]\n",
      "Vector y: [4 5 6]\n",
      "Euclidean distance: 5.1962\n",
      "Manhattan distance: 9.0000\n",
      "Cosine similarity: 0.9746\n"
     ]
    }
   ],
   "source": [
    "# Euclidean distance between vectors\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Manhattan distance\n",
    "def manhattan_distance(x, y):\n",
    "    return np.sum(np.abs(x - y))\n",
    "\n",
    "# Cosine similarity\n",
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "# Test with sample vectors\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "print(f\"Vector x: {x}\")\n",
    "print(f\"Vector y: {y}\")\n",
    "print(f\"Euclidean distance: {euclidean_distance(x, y):.4f}\")\n",
    "print(f\"Manhattan distance: {manhattan_distance(x, y):.4f}\")\n",
    "print(f\"Cosine similarity: {cosine_similarity(x, y):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Covariance\n",
    "\n",
    "**Use Case**: Feature selection, multicollinearity detection, understanding feature relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:\n",
      "[[2.5  1.5  4.  ]\n",
      " [1.5  1.5  2.75]\n",
      " [4.   2.75 6.7 ]]\n",
      "\n",
      "Correlation matrix:\n",
      "[[1.         0.77459667 0.97735555]\n",
      " [0.77459667 1.         0.86746041]\n",
      " [0.97735555 0.86746041 1.        ]]\n",
      "\n",
      "Correlation (feature1, target): 0.9774\n",
      "Correlation (feature2, target): 0.8675\n"
     ]
    }
   ],
   "source": [
    "# Sample data: features vs target\n",
    "feature1 = np.array([1, 2, 3, 4, 5])\n",
    "feature2 = np.array([2, 4, 5, 4, 5])\n",
    "target = np.array([3, 6, 7, 8, 10])\n",
    "\n",
    "# Covariance matrix\n",
    "data_matrix = np.vstack([feature1, feature2, target])\n",
    "cov_matrix = np.cov(data_matrix)\n",
    "print(f\"Covariance matrix:\\n{cov_matrix}\\n\")\n",
    "\n",
    "# Correlation matrix (normalized covariance)\n",
    "corr_matrix = np.corrcoef(data_matrix)\n",
    "print(f\"Correlation matrix:\\n{corr_matrix}\\n\")\n",
    "\n",
    "# Individual correlation\n",
    "corr_f1_target = np.corrcoef(feature1, target)[0, 1]\n",
    "corr_f2_target = np.corrcoef(feature2, target)[0, 1]\n",
    "print(f\"Correlation (feature1, target): {corr_f1_target:.4f}\")\n",
    "print(f\"Correlation (feature2, target): {corr_f2_target:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Indexing for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations with target: [ 0.1090727   0.07381451  0.10516154 -0.15846464 -0.02222396 -0.02626849\n",
      "  0.1902869  -0.1211623   0.01169213  0.04533784]\n",
      "\n",
      "Feature mask: [False False False False False False False False False False]\n",
      "Selected features: []\n",
      "\n",
      "Original shape: (100, 10)\n",
      "Selected shape: (100, 0)\n"
     ]
    }
   ],
   "source": [
    "# Feature matrix with correlation to target\n",
    "X = np.random.randn(100, 10)  # 100 samples, 10 features\n",
    "y = np.random.randn(100)\n",
    "\n",
    "# Calculate correlation of each feature with target\n",
    "correlations = np.array([np.corrcoef(X[:, i], y)[0, 1] for i in range(X.shape[1])])\n",
    "print(f\"Correlations with target: {correlations}\")\n",
    "\n",
    "# Select features with |correlation| > 0.2\n",
    "feature_mask = np.abs(correlations) > 0.2\n",
    "print(f\"\\nFeature mask: {feature_mask}\")\n",
    "print(f\"Selected features: {np.where(feature_mask)[0]}\")\n",
    "\n",
    "# Apply feature selection\n",
    "X_selected = X[:, feature_mask]\n",
    "print(f\"\\nOriginal shape: {X.shape}\")\n",
    "print(f\"Selected shape: {X_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving Linear Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [2. 3.]\n",
      "Verification (A @ x): [9. 8.]\n",
      "\n",
      "Least squares solution: [0.66666667 0.5       ]\n",
      "Residuals: [0.16666667]\n"
     ]
    }
   ],
   "source": [
    "# Solve Ax = b\n",
    "A = np.array([[3, 1], [1, 2]])\n",
    "b = np.array([9, 8])\n",
    "\n",
    "x = np.linalg.solve(A, b)\n",
    "print(f\"Solution: {x}\")\n",
    "print(f\"Verification (A @ x): {A @ x}\")\n",
    "\n",
    "# Least squares solution (overdetermined system)\n",
    "A_over = np.array([[1, 1], [1, 2], [1, 3]])\n",
    "b_over = np.array([1, 2, 2])\n",
    "\n",
    "x_ls, residuals, rank, s = np.linalg.lstsq(A_over, b_over, rcond=None)\n",
    "print(f\"\\nLeast squares solution: {x_ls}\")\n",
    "print(f\"Residuals: {residuals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U shape: (2, 2)\n",
      "Singular values: [9.508032   0.77286964]\n",
      "VT shape: (3, 3)\n",
      "\n",
      "Reconstructed:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# SVD: A = U @ S @ V^T\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "U, s, VT = np.linalg.svd(A)\n",
    "print(f\"U shape: {U.shape}\")\n",
    "print(f\"Singular values: {s}\")\n",
    "print(f\"VT shape: {VT.shape}\")\n",
    "\n",
    "# Reconstruct matrix\n",
    "S = np.zeros_like(A, dtype=float)\n",
    "S[:len(s), :len(s)] = np.diag(s)\n",
    "A_reconstructed = U @ S @ VT\n",
    "print(f\"\\nReconstructed:\\n{A_reconstructed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norms and Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm: 7.0\n",
      "L2 norm: 5.0\n",
      "L-infinity norm: 4.0\n",
      "\n",
      "Frobenius norm: 5.477225575051661\n"
     ]
    }
   ],
   "source": [
    "# Vector norms\n",
    "v = np.array([3, 4])\n",
    "\n",
    "print(f\"L1 norm: {np.linalg.norm(v, ord=1)}\")      # Manhattan\n",
    "print(f\"L2 norm: {np.linalg.norm(v)}\")             # Euclidean\n",
    "print(f\"L-infinity norm: {np.linalg.norm(v, ord=np.inf)}\")\n",
    "\n",
    "# Matrix norms\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "print(f\"\\nFrobenius norm: {np.linalg.norm(A, 'fro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binomial mean: 4.94 (expected: 5.0)\n",
      "Poisson mean: 4.98 (expected: 5.0)\n",
      "Exponential mean: 1.87 (expected: 2.0)\n",
      "Beta mean: 0.28 (expected: 0.29)\n"
     ]
    }
   ],
   "source": [
    "# Common distributions in ML\n",
    "np.random.seed(42)\n",
    "\n",
    "# Binomial (e.g., coin flips)\n",
    "binomial = np.random.binomial(n=10, p=0.5, size=1000)\n",
    "print(f\"Binomial mean: {binomial.mean():.2f} (expected: 5.0)\")\n",
    "\n",
    "# Poisson (e.g., event counts)\n",
    "poisson = np.random.poisson(lam=5, size=1000)\n",
    "print(f\"Poisson mean: {poisson.mean():.2f} (expected: 5.0)\")\n",
    "\n",
    "# Exponential (e.g., time between events)\n",
    "exponential = np.random.exponential(scale=2, size=1000)\n",
    "print(f\"Exponential mean: {exponential.mean():.2f} (expected: 2.0)\")\n",
    "\n",
    "# Beta distribution (useful for Bayesian methods)\n",
    "beta = np.random.beta(a=2, b=5, size=1000)\n",
    "print(f\"Beta mean: {beta.mean():.2f} (expected: {2/(2+5):.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Base (DSML)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
